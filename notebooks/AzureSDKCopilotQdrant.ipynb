{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68e1c158",
   "metadata": {},
   "source": [
    "# Building Semantic Memory with Embeddings\n",
    "\n",
    "So far, we've mostly been treating the kernel as a stateless orchestration engine.\n",
    "We send text into a model API and receive text out. \n",
    "\n",
    "In a [previous notebook](04-context-variables-chat.ipynb), we used `context variables` to pass in additional\n",
    "text into prompts to enrich them with more context. This allowed us to create a basic chat experience. \n",
    "\n",
    "However, if you solely relied on context variables, you would quickly realize that eventually your prompt\n",
    "would grow so large that you would run into a the model's token limit. What we need is a way to persist state\n",
    "and build both short-term and long-term memory to empower even more intelligent applications. \n",
    "\n",
    "To do this, we dive into the key concept of `Semantic Memory` in the Semantic Kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77bdf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install semantic-kernel==0.2.7.dev0\n",
    "# !python -m pip install qdrant-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04f8364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import re, asyncio\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Filter, FieldCondition, MatchValue\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureTextEmbedding, AzureChatCompletion\n",
    "from semantic_kernel.connectors.ai.chat_request_settings import ChatRequestSettings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425803a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "\n",
    "embedding_generator = AzureTextEmbedding(\"text-embedding-ada-002\", endpoint, api_key)\n",
    "\n",
    "system_message = \"\"\"\n",
    "You are AZSDK_Bot, an expert on Azure SDKs. \n",
    "You can answer questions about Azure SDKs and provide links to relevant repositories based on the context provided in prompts.\n",
    "Prioritize the content in the prompt when answering questions. The link to the repo should be taken from the prompt.\n",
    "Whenever you see '/master/' in a prompt, replace it with '/main/'. Do not modify the URL in any other way.\n",
    "\"\"\"\n",
    "\n",
    "chat_service = AzureChatCompletion(deployment, endpoint, api_key)\n",
    "\n",
    "# List of text samples to generate embeddings for\n",
    "texts = \"This is a test of the emergency broadcast system. This is only a test. If this had been an actual emergency Id be running for my life\"\n",
    "\n",
    "# Arbitrary question to ask the chatbot for testing purposes\n",
    "question = \"What can you tell me about the Azure SDK for Rust?\"\n",
    "\n",
    "# Define the async function to get embeddings. Include retry logic to account for rate limit errors.\n",
    "# async def create_embedding(data):\n",
    "#     MAX_RETRIES = 3\n",
    "#     retry_count = 0\n",
    "\n",
    "#     while retry_count < MAX_RETRIES:\n",
    "#         embeddings = await embedding_generator.generate_embeddings_async(data)\n",
    "#         if \"exceeded call rate limit\" in str(embeddings):\n",
    "#             error_message = str(embeddings)\n",
    "#             delay_str = re.search(r'Please retry after (\\d+)', error_message)\n",
    "#             if delay_str:\n",
    "#                 delay = int(delay_str.group(1))\n",
    "#                 print(f\"Rate limit exceeded. Retrying in {delay} seconds...\")\n",
    "#                 await asyncio.sleep(delay)\n",
    "#                 retry_count += 1\n",
    "#             else:\n",
    "#                 raise Exception(\"Unknown error message when creating embeddings.\")\n",
    "#         else:\n",
    "#             return embeddings\n",
    "\n",
    "#     raise Exception(\"Rate limit error. All retries failed.\")\n",
    "\n",
    "async def create_embedding(data):\n",
    "    MAX_RETRIES = 5\n",
    "    retry_count = 0\n",
    "\n",
    "    while retry_count < MAX_RETRIES:\n",
    "        try:\n",
    "            embeddings = await embedding_generator.generate_embeddings_async(data)\n",
    "            return embeddings\n",
    "        except Exception as e:\n",
    "            error_message = str(e)\n",
    "            if \"exceeded call rate limit\" in error_message:\n",
    "                delay_str = re.search(r'Please retry after (\\d+)', error_message)\n",
    "                if delay_str:\n",
    "                    delay = int(delay_str.group(1))\n",
    "                    print(f\"Rate limit exceeded. Retrying in {delay} seconds...\")\n",
    "                    await asyncio.sleep(delay)\n",
    "                    retry_count += 1\n",
    "                else:\n",
    "                    raise Exception(\"Unknown error message when creating embeddings.\")\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "    raise Exception(\"Rate limit error. All retries failed.\")\n",
    "\n",
    "\n",
    "# Define the async function to ask the chatbot. This will be used to generate a response to the user's question from relevant README content\n",
    "async def ask_chatbot(input):\n",
    "    messages = [(\"system\", system_message), (\"user\", input)]\n",
    "    reply = await chat_service.complete_chat_async(messages=messages, request_settings=ChatRequestSettings(temperature=0.7, top_p=0.8, max_tokens=2000))\n",
    "    return(reply)\n",
    "\n",
    "# Test the embedding generator\n",
    "result = await create_embedding(texts)\n",
    "print(result)\n",
    "\n",
    "# Test the chatbot\n",
    "reply = await ask_chatbot(question)\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812cc2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qdrant_client = QdrantClient(path=r\"C:\\Users\\marioguerra\\Work\\semantic-kernel\\python\\semantic_kernel\\memory\")\n",
    "\n",
    "async def query_qdrant(user_input, collection_name, language):\n",
    "    print(\"Querying Qdrant with input: \", user_input)\n",
    "    embedding = await create_embedding(user_input)\n",
    "    vector_embedding = embedding.tolist()\n",
    "    search_results = qdrant_client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=vector_embedding[0],\n",
    "        query_filter=Filter(\n",
    "            must=[  \n",
    "                FieldCondition(\n",
    "                    key='language',\n",
    "                    match=MatchValue(value=language)\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit=1,\n",
    "        # score_threshold=0.75,\n",
    "    )\n",
    "    return search_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeb862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of the code in the chat function:\n",
    "# 1. Define regex patterns for different languages\n",
    "# 2. Define the chat() function as an asynchronous function that takes\n",
    "#    kernel, context, and previous_input as arguments\n",
    "# 3. Inside the chat() function, check if the user input matches more than one\n",
    "#    language and ask the user to focus on one language at a time if true\n",
    "# 4. If the user input matches a single language, call the query_qdrant()\n",
    "#    function with the matched language to find READMEs relevant to question\n",
    "# 5. Handle the case where the user input does not match any language and\n",
    "#    append the user input to the previous_input string, since this is most\n",
    "#    likely a follow up question about the same SDK as previous question\n",
    "# 6. If the length of the previous_input string exceeds 10,000 characters,\n",
    "#    trim it to keep only the last 10,000 characters to keep within our\n",
    "#    context limit (admittedly arbitrary, since I don't know the exact limit)\n",
    "# 7. Update the previous_input string with the new context and provide the\n",
    "#    chatbot answer at the end of each iteration\n",
    "\n",
    "rust = r'^\\/(rust).*$'\n",
    "python = r'^\\/(python|Python).*$'\n",
    "java = r'^\\/(java|Java).*$'\n",
    "js = r'^\\/(javascript|js|Javacript|JavaScript|JS).*$'\n",
    "net = r'^\\/(\\.net|net|\\.NET|NET|csharp|C#).*$'\n",
    "\n",
    "async def chat(kernel: sk.Kernel, context: sk.ContextVariables, previous_input: str) -> Tuple[bool, str, str]:\n",
    "    try:\n",
    "        user_input = input(\"User:> \")\n",
    "        print(f\"User:> {user_input}\")\n",
    "\n",
    "        if (user_input != \"\"):\n",
    "            language_matches = {\n",
    "                \"Rust\": bool(re.match(rust, user_input, re.IGNORECASE)),\n",
    "                \"Python\": bool(re.match(python, user_input, re.IGNORECASE)),\n",
    "                \"Java\": bool(re.match(java, user_input, re.IGNORECASE)),\n",
    "                \"JavaScript\": bool(re.match(js, user_input, re.IGNORECASE)),\n",
    "                \".NET\": bool(re.match(net, user_input, re.IGNORECASE)),\n",
    "            }\n",
    "\n",
    "            matches = sum(language_matches.values())\n",
    "\n",
    "            if matches > 1:\n",
    "                print(\"AZSDK_Bot:> Please, one language at a time!\")\n",
    "                return True, user_input, previous_input\n",
    "\n",
    "            if matches:\n",
    "                language = [lang for lang, matched in language_matches.items() if matched][0]\n",
    "                print(\"language: \", language)\n",
    "\n",
    "                search_results = await query_qdrant(user_input, \"AzureSDKs\", language)\n",
    "                print(\"qdrant search results: \", search_results)\n",
    "                if search_results:\n",
    "                    for result in search_results:\n",
    "                        payload = result.payload\n",
    "                        sdk = payload[\"SDK\"]\n",
    "                        # print(f\"SDK:> {sdk}\")\n",
    "                        link_to_repo = payload[\"link_to_repo\"]\n",
    "                        # print(f\"Link to repo:> {link_to_repo}\")\n",
    "                        language = payload[\"language\"]\n",
    "                        readme_text = payload[\"README_text\"][:10000]\n",
    "                    context_prompt = user_input + str(readme_text) + str(link_to_repo) + str(language) + str(sdk)\n",
    "                else:\n",
    "                    context_prompt = \"No results found for this query.\"\n",
    "            else:\n",
    "                if len(previous_input) > 10000:\n",
    "                    previous_input = previous_input[-10000:]\n",
    "                context_prompt = previous_input + user_input        \n",
    "        else:\n",
    "            if not previous_input: # \n",
    "                context_prompt = \"Tell me about Azure SDKs.\"\n",
    "            else:\n",
    "                context_prompt = previous_input + \"\\n\\nTell me about this Azure SDK.\"\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nExiting chat...\")\n",
    "        return False, \"\", \"\"\n",
    "    except EOFError:\n",
    "        print(\"\\n\\nExiting chat...\")\n",
    "        return False, \"\", \"\"\n",
    "    if user_input == \"exit\":\n",
    "        print(\"\\n\\nExiting chat...\")\n",
    "        return False, \"\", \"\"\n",
    "    print(\"Thinking...\")\n",
    "    answer = await ask_chatbot(context_prompt)\n",
    "    previous_input = context_prompt + answer\n",
    "    print(f\"AZSDK_Bot:> {answer}\")\n",
    "    return True, user_input, previous_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d36f5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = sk.ContextVariables()\n",
    "print(\"Begin chatting (type 'exit' to exit):\\n\")\n",
    "previous_input = \"\"\n",
    "chatting = True\n",
    "while chatting:\n",
    "    chatting, context, previous_input = await chat(kernel, context, previous_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
